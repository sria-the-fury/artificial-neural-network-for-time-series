{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU5-zf5Ad3k3"
   },
   "source": [
    "After observing the yahoo finance package, found some days' closing price are not correct. So, the extra script help to fix the data. There is no need to download and fix manully everytime. I already email to the yahoo finance to fix this data. If they fix, then there will be no use of this first script in future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi5GaAFCD3eJ",
    "outputId": "78902d70-f719-4abb-c538-306d3594ec50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EUR/USD data...\n",
      "Flattening columns...\n",
      "\n",
      "Applying corrections...\n",
      "Fixing 2008-01-08: Old=1.5571 -> New=1.4705\n",
      "Fixing 2008-02-08: Old=1.5571 -> New=1.4503\n",
      "Fixing 2008-08-08: Old=1.5049 -> New=1.5074\n",
      "Fixing 2008-09-08: Old=1.5050 -> New=1.4250\n",
      "Fixing 2008-10-08: Old=1.4957 -> New=1.3650\n",
      "Fixing 2008-12-08: Old=1.4918 -> New=1.2930\n",
      "\n",
      "Done. Saved to ../results/EURUSD_Close_Fixed_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def download_and_fix_eurusd_close():\n",
    "    # Download EUR/USD data\n",
    "    print(\"Downloading EUR/USD data...\")\n",
    "    ticker = \"EURUSD=X\"\n",
    "    df = yf.download(ticker, start=\"2000-01-01\", end=\"2023-12-31\", progress=False)\n",
    "\n",
    "    df = df[['Close']].copy()\n",
    "\n",
    "    # Flatten columns if multi-index (common in yfinance)\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        print(\"Flattening columns...\")\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "    # Taken from https://www.kaggle.com/datasets/lehenzehra/eurusd-daily-data-ohlc?select=EURUSD_D1_Sorted.csv\n",
    "    corrections = {\n",
    "        \"2008-01-08\": 1.4705,\n",
    "        \"2008-02-08\": 1.4503,\n",
    "        \"2008-08-08\": 1.5074,\n",
    "        \"2008-09-08\": 1.4250,\n",
    "        \"2008-10-08\": 1.3650,\n",
    "        \"2008-12-08\": 1.2930,\n",
    "    }\n",
    "\n",
    "    print(\"\\nApplying corrections...\")\n",
    "\n",
    "    # Apply corrections\n",
    "    for date_str, price in corrections.items():\n",
    "        dt = pd.Timestamp(date_str)\n",
    "        if dt in df.index:\n",
    "            print(f\"Fixing {date_str}: Old={df.at[dt, 'Close']:.4f} -> New={price:.4f}\")\n",
    "            df.at[dt, 'Close'] = price\n",
    "        else:\n",
    "            print(f\"Warning: {date_str} not found in data.\")\n",
    "\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = \"../results/EURUSD_Close_Fixed_2023.csv\"\n",
    "    df.to_csv(output_file)\n",
    "    print(f\"\\nDone. Saved to {output_file}\")\n",
    "\n",
    "\n",
    "download_and_fix_eurusd_close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKtUL89vecY7"
   },
   "source": [
    "Load the corrected data and make a 'difference' percentafge column based on the closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2vHKLCk2Px_2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../results/EURUSD_Close_Fixed_2023.csv\", index_col=0, parse_dates=True)\n",
    "df['difference'] = df['Close'].pct_change() * 100\n",
    "df.head()\n",
    "df.to_csv('../results/EURUSD_Close_Fixed_with_difference_2023.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtUAKNsQeqt4"
   },
   "source": [
    "The main script started from here. Creating main data table for calculating Euclidean Distane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82ea1b91",
    "outputId": "0a896f58-eeed-44e0-f712-3cf1ec00b21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'main_data_table_2023.csv'.\n"
     ]
    }
   ],
   "source": [
    "data = df['difference'].dropna().tolist()\n",
    "\n",
    "main_data_rows = []\n",
    "window_size = 6\n",
    "\n",
    "# Iterate through the data to create feature vectors and target values\n",
    "for i in range(len(data) - window_size + 1):\n",
    "    row = data[i : i + window_size]\n",
    "    feature_vector = row[:5]\n",
    "    true_value = row[5]\n",
    "    main_data_rows.append(feature_vector + [true_value])\n",
    "\n",
    "# Create column names for the new DataFrame\n",
    "column_names = [f'p{j+1}' for j in range(5)] + ['true_value_next_day']\n",
    "\n",
    "# Create the 'main_data' DataFrame\n",
    "main_data = pd.DataFrame(main_data_rows, columns=column_names)\n",
    "\n",
    "# Set the DataFrame index to start from 1\n",
    "main_data.index = range(1, len(main_data) + 1)\n",
    "\n",
    "#Saving \"Main Data Table\"\n",
    "main_data.to_csv('../results/main_data_table_2023.csv', index_label='Vectors')\n",
    "print(\"Saved 'main_data_table_2023.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoz5ePjde70h"
   },
   "source": [
    "After forming the \"difference\" column as vectors, calcultaing the Euclidean Distance. And do statics of the positive and negative outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4G9MVyjDbRZX",
    "outputId": "cdc41634-21e1-43bd-b5ef-6e24a6ba0bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted results will be saved to 'final_result_df.txt' upon execution.\n"
     ]
    }
   ],
   "source": [
    "def writeInText(accepted_results_df, B, threshold, positive_percentage, negative_percentage):\n",
    "  with open('../results/final_result_df_2023.txt', 'a') as f:\n",
    "    f.write(\"L set:\\n\")\n",
    "    for index, row in accepted_results_df.iterrows():\n",
    "        # Assuming column 0 is the feature vector list and column 1 is v_target\n",
    "        feature_vector_str = ', '.join(map(str, row[0]))\n",
    "        v_target_val = row[1]\n",
    "        f.write(f\"[{feature_vector_str}, {v_target_val}]\\n\")\n",
    "\n",
    "    f.write(\"B vector:\\n\")\n",
    "    # Explicitly format B as comma-separated string without spaces\n",
    "    f.write(f\"[{','.join(map(str, B))}]\")\n",
    "\n",
    "    f.write(\"\\nτ value:\\n\")\n",
    "    f.write(f\"{threshold:.1f}\")\n",
    "\n",
    "    f.write(\"\\n% of positive vtarget:\\n\")\n",
    "    f.write(f\"{positive_percentage:.2f}\")\n",
    "\n",
    "    f.write(\"\\n% of negative vtarget:\\n\")\n",
    "    f.write(f\"{negative_percentage:.2f}\")\n",
    "\n",
    "    f.write(\"\\n\\n-------------------------------\\n\\n\")\n",
    "print(\"Formatted results will be saved to 'final_result_df.txt' upon execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoqDsVKMXsCf",
    "outputId": "8f9d058d-60b0-4a11-c39a-636bf9ffe2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading generated base vectors from ../results/base_vectors/generated_base_vectors.txt\n",
      "Started at => 2026-02-16 12:55:18.590672\n",
      "\n",
      "-----Calculating Euclidean Distance-----\n",
      "\n",
      "T: --> 0.5--> 0.6--> 0.7--> 0.8--> 0.9--> 1.0--> 1.1--> 1.2--> 1.3--> 1.4--> 1.5\n",
      "Finished at => 2026-02-16 13:30:14.132168\n",
      "Total time take => 0:34:55.541496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Define the filename for storing generated base vectors\n",
    "base_vectors_file = '../results/base_vectors/generated_base_vectors.txt'\n",
    "\n",
    "# Ensure generated_base_vectors is created only once per kernel session and persisted\n",
    "if os.path.exists(base_vectors_file):\n",
    "    print(f\"Loading generated base vectors from {base_vectors_file}\")\n",
    "    generated_base_vectors = np.loadtxt(base_vectors_file)\n",
    "    # Reshape if only a single vector was saved (loadtxt might flatten it)\n",
    "    if generated_base_vectors.ndim == 1:\n",
    "        generated_base_vectors = generated_base_vectors.reshape(1, -1)\n",
    "else:\n",
    "    print(\"Generating new base vectors and saving them.\")\n",
    "    generated_base_vectors = np.random.uniform(low=-2.0, high=2.0, size=(50, 5))\n",
    "    np.savetxt(base_vectors_file, generated_base_vectors)\n",
    "\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"Started at => {start_time}\")\n",
    "print(f\"\\n-----Calculating Euclidean Distance-----\\n\")\n",
    "print(\"T: \", end=\"\")\n",
    "\n",
    "# Clear the file before starting to avoid appending to previous runs\n",
    "with open('../results/final_result_df_2023.txt', 'w') as f:\n",
    "    pass\n",
    "\n",
    "for current_threshold in np.arange(0.5, 1.51, 0.1):\n",
    "    print(f\"--> {current_threshold:.1f}\", end=\"\")\n",
    "\n",
    "    # Iterate through each generated base vector\n",
    "    for gen_base_vec_idx in range(generated_base_vectors.shape[0]):\n",
    "        current_base_vector = generated_base_vectors[gen_base_vec_idx]\n",
    "        accepted_results_list = [] # Reset for each base vector within a threshold\n",
    "\n",
    "        for index, row in main_data.iterrows():\n",
    "            feature_vector = np.array(row[['p1', 'p2', 'p3', 'p4', 'p5']].tolist())\n",
    "            euclidean_distance = np.linalg.norm(feature_vector - current_base_vector)\n",
    "            v_target = 0;\n",
    "\n",
    "            if euclidean_distance < current_threshold:\n",
    "                v_target = row['true_value_next_day']\n",
    "\n",
    "                # Modified: Append a list [feature_vector, v_target]\n",
    "                accepted_results_list.append([feature_vector.tolist(), v_target])\n",
    "\n",
    "        if accepted_results_list:\n",
    "            # Modified: Create DataFrame with explicit column names\n",
    "            accepted_results_df_without_col =  pd.DataFrame(accepted_results_list)\n",
    "\n",
    "            accepted_results_df = pd.DataFrame(accepted_results_list, columns=['r1', 'v_target'])\n",
    "            positive_count = (accepted_results_df['v_target'] > 0).sum()\n",
    "            negative_count = (accepted_results_df['v_target'] <= 0).sum()\n",
    "            positive_percentage=(positive_count/len(accepted_results_df))*100\n",
    "            negative_percentage=(negative_count/len(accepted_results_df))*100\n",
    "\n",
    "            writeInText(accepted_results_df_without_col, current_base_vector.tolist(), current_threshold, positive_percentage, negative_percentage)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"\\nFinished at => {end_time}\")\n",
    "print(f\"Total time take => {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     L_set_count threshold_value  \\\n",
      "359         2862             1.5   \n",
      "310         2425             1.4   \n",
      "264         1975             1.3   \n",
      "218         1518             1.2   \n",
      "366         1371             1.5   \n",
      "\n",
      "                                                                                                 B_vector  \\\n",
      "359   [0.6673177879279355,-0.399743965085662,0.1166337339292971,-0.4774067929209176,-0.38544785593128283]   \n",
      "310   [0.6673177879279355,-0.399743965085662,0.1166337339292971,-0.4774067929209176,-0.38544785593128283]   \n",
      "264   [0.6673177879279355,-0.399743965085662,0.1166337339292971,-0.4774067929209176,-0.38544785593128283]   \n",
      "218   [0.6673177879279355,-0.399743965085662,0.1166337339292971,-0.4774067929209176,-0.38544785593128283]   \n",
      "366  [-1.1523272049025688,0.5411143749381351,0.1461269041420521,-0.06325676014369375,-0.6721807878932626]   \n",
      "\n",
      "    percent_positive percent_negative  \n",
      "359            50.98            49.02  \n",
      "310            51.51            48.49  \n",
      "264            51.80            48.20  \n",
      "218            51.58            48.42  \n",
      "366            50.04            49.96  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_full_info_sorted(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Split content by the separator line\n",
    "    blocks = content.split('-------------------------------')\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for block in blocks:\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        \n",
    "        lines = [line.strip() for line in block.strip().split('\\n')]\n",
    "        \n",
    "        record = {\n",
    "            'L_set_count': 0,\n",
    "            'threshold_value': None,\n",
    "            'B_vector': None,\n",
    "            'percent_positive': None,\n",
    "            'percent_negative': None\n",
    "        }\n",
    "        \n",
    "        # Extract Threshold (τ value)\n",
    "        if 'τ value:' in lines:\n",
    "            idx = lines.index('τ value:')\n",
    "            if idx + 1 < len(lines):\n",
    "                record['threshold_value'] = lines[idx+1]\n",
    "        \n",
    "        # Extract B Vector (Full String)\n",
    "        if 'B vector:' in lines:\n",
    "            idx = lines.index('B vector:')\n",
    "            if idx + 1 < len(lines):\n",
    "                record['B_vector'] = lines[idx+1]\n",
    "\n",
    "        # Extract Percentages\n",
    "        if '% of positive vtarget:' in lines:\n",
    "            idx = lines.index('% of positive vtarget:')\n",
    "            if idx + 1 < len(lines):\n",
    "                record['percent_positive'] = lines[idx+1]\n",
    "                \n",
    "        if '% of negative vtarget:' in lines:\n",
    "            idx = lines.index('% of negative vtarget:')\n",
    "            if idx + 1 < len(lines):\n",
    "                record['percent_negative'] = lines[idx+1]\n",
    "\n",
    "        # Count L Set Vectors\n",
    "        if 'L set:' in lines and 'B vector:' in lines:\n",
    "            try:\n",
    "                l_start = lines.index('L set:')\n",
    "                b_start = lines.index('B vector:')\n",
    "                \n",
    "                count = 0\n",
    "                # Count lines starting with '[' between labels\n",
    "                for i in range(l_start + 1, b_start):\n",
    "                    if lines[i].startswith('['):\n",
    "                        count += 1\n",
    "                record['L_set_count'] = count\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        # Only add records with valid B_vector\n",
    "        if record['B_vector'] is not None:\n",
    "            data.append(record)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Sort by count descending\n",
    "    if not df.empty:\n",
    "        df_sorted = df.sort_values(by='L_set_count', ascending=False)\n",
    "        return df_sorted\n",
    "    return df\n",
    "\n",
    "# Configure Pandas to show full column width\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Usage\n",
    "file_name = '../results/final_result_df_2023.txt'\n",
    "df_final = parse_full_info_sorted(file_name)\n",
    "\n",
    "# Select desired columns\n",
    "columns_to_show = ['L_set_count', 'threshold_value', 'B_vector', 'percent_positive', 'percent_negative']\n",
    "print(df_final[columns_to_show].head())\n",
    "\n",
    "# Save to CSV\n",
    "df_final[columns_to_show].to_csv('../results/sorted_l_set_full_info.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
